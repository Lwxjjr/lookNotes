# 键值对数据库是怎么实现的？
Redis 是使用了一个「==哈希表==」保存所有键值对  
哈希表其实就是一个数组，数组中的元素叫做==哈希桶==  
哈希桶存放的是==指向键值对数据的指针（dictEntry*）==，这样通过指针就能找到键值对数据

![[f302fce6c92c0682024f47bf7579b44c.webp]]
- ==redisDb 结构==，Redis ==数据库的结构==，结构体里存放了指向了 dict 结构的指针；
- ==dict 结构==，存放了 2 个哈希表，正常情况下都是用「哈希表1」，「哈希表2」只有在 rehash 的时候才用
- ==ditctht 结构==，表示==哈希表的结构==，结构里存放了哈希表数组，数组中的每个元素都是指向一个哈希表节点结构（dictEntry）的指针；
- ==dictEntry 结构==，表示哈希表节点的结构，结构里存放了 **void * key 和 void * value 指针， _key 指向的是 String 对象，而 _value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象__

每种显式类型都有对应的==隐式实际类型==，如embstr、raw、hashtable、ziplist、quicklist和skiplist  
void * key 和 void * value 指针指向的是 ==**Redis 对象**==，Redis 中的每个对象都由 redisObject 结构表示  
Redis存储的数据是由**redisObject**结构体构成的 
# redisObject
Redis存储数据不是简单粗暴地直接使用C语言原始基础数据类型，  
而是根据自身设计理念自定义存储对象（结构体）
```c
typedef struct redisObject {
    unsigned type:4;       // 对象类型（显式类型）
    unsigned encoding:4;   // 对象编码（隐式类型）
    unsigned lru:LRU_BITS; // 对象最后一次访问时间（秒）
    int refcount;          // 引用计数。0：可被垃圾回收
    void *ptr;             // 指向实际的数据存储结构
} robj;
```
![[58d3987af2af868dca965193fb27c464 1.webp|500]]
## type与encoding对应关系
![[Pasted image 20250318190000.png]]
## Redis键值对全景图
![[3c386666e4e7638a07b230ba14b400fe.webp]]

---
# SDS
Redis 是用 C 语言实现的，但是它没有直接使用 C 语言的 char* 字符数组来实现字符串，而是自己封装了一个名为==简单动态字符串（simple dynamic string，SDS）==的数据结构来表示字符串
## C 语言字符串的缺陷
### 1. "\0"的提前结束
C 语言的字符串其实就是一个字符数组，即数组中每个元素是字符串中的一个字符。比如，下图就是字符串“xiaolin”的 char* 字符数组的结构：

![](https://cdn.xiaolincoding.com//mysql/other/376128646c75a893ad47914858fa2131.png)
char * 指针只是指向字符数组的起始位置，**字符数组的结尾位置就用“\0”表示，意思是指字符串的结束**，==通过"\0"来判断是否继续操作字符串==  
C语音获取字符串长度的函数`strlen`实际就是把字符数组遍历一遍计数，直到遇到"\0"  
1. **C 语言获取字符串长度的时间复杂度是 ==O（N）==** 
2. ==二进制不安全==，这个限制使得 C 语言的字符串只能保存文本数据，**不能保存像图片、音频、视频文化这样的二进制数据**  
### 2. 操作函数不安全
1. ==**C 语言的字符串是不会记录自身的缓冲区大小的**==，所以 strcat 函数假定程序员在执行这个函数时，已经为 dest 分配了足够多的内存，可以容纳 src 字符串中的所有内容，而==**一旦这个假定不成立，就会发生缓冲区溢出将可能会造成程序运行终止**==
2. ==**对字符串的操作效率不高**==
## SDS 结构设计
SDS的数据结构：

![[516738c4058cdf9109e40a7812ef4239.webp]]
- **len，记录了字符串长度**（取字符串长度的时间复杂度为O(1))
- **alloc，分配给字符数组的空间长度**（在修改字符串的时候，可以通过 ==`alloc - len` 计算出剩余的空间大小==，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间==扩展至执行修改所需的大小==）
- **flags，用来表示不同类型的 SDS**
- **buf[]，字节数组，用来保存实际数据**（SDS对上层暴露的指针不是指向结构体SDS的指针，而是直接指向柔性数据buf的指针）
### SDS对比C语言字符串的优点：
1. ==O（1）复杂度==获取字符串长度
2. ==二进制安全==，不需要用 “\0” 字符来标识字符串结尾了
3. ==不会发生缓冲区溢出==，当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小，以满足修改所需的大小。
```c
hisds hi_sdsMakeRoomFor(hisds s, size_t addlen)
{
    ... ...
    // s目前的剩余空间已足够，无需扩展，直接返回
    if (avail >= addlen)
        return s;
    //获取目前s的长度
    len = hi_sdslen(s);
    sh = (char *)s - hi_sdsHdrSize(oldtype);
    //扩展之后 s 至少需要的长度
    newlen = (len + addlen);
    //根据新长度，为s分配新空间所需要的大小
    if (newlen < HI_SDS_MAX_PREALLOC)
        //新长度<HI_SDS_MAX_PREALLOC 则分配所需空间*2的空间
        newlen *= 2;
    else
        //否则，分配长度为目前长度+1MB
        newlen += HI_SDS_MAX_PREALLOC;
       ...
}
```

- 如果所需的 sds 长度**小于 1 MB**，那么最后的扩容是按照**翻倍扩容**来执行的，即 2 倍的newlen
- 如果所需的 sds 长度**超过 1 MB**，那么最后的扩容长度应该是 newlen **+ 1MB**
小容量时按倍数扩展
针对小容量时按倍数扩展的策略主要是为了==高效应对快速增长和减少内存分配次数==，而在大容量时采用加法拓展则是==为了控制内存使用、稳定增长并减少内存浪费==。这样的策略能够兼顾性能和效率

### flags —— SDS类型
SDS 结构中有个 flags 成员变量，表示的是 ==SDS 类型==  
分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64  
主要区别就在于，它们数据结构中的 ==len 和 alloc 成员变量的数据类型不同==
## 节省空间
1. ==**之所以 SDS 设计不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间**==
2. Redis 在编程上还==**使用了专门的编译优化来节省内存空间**==**，即在 struct 声明了 `__attribute__ ((packed))`，告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐**



---
# 链表
Redis 的 List 对象的底层实现之一就是链表
## 链表节点结构设计（双向链表）
```c
typedef struct listNode {
    struct listNode *prev;    //前置节点
    struct listNode *next;    //后置节点
    void *value;              //节点的值
} listNode;
```
## 链表结构设计（封装list）
```c
typedef struct list {
    listNode *head;                        //链表头节点
    listNode *tail;                        //链表尾节点
    void *(*dup)(void *ptr);               //节点值复制函数
    void (*free)(void *ptr);               //节点值释放函数
    int (*match)(void *ptr, void *key);    //节点值比较函数
    unsigned long len;                     //链表节点数量
} list;
```
![[cadf797496816eb343a19c2451437f1e.webp]]
## 链表的优势与缺陷

优点：
1. listNode的prev和next指针保证获取前置后置节点的时间复杂度为O(1)
2. list的head和tail指针保证获取表头和表尾节点的时间复杂度为O(1)
3. listNode链表节点可以保存各种不同类型的值  

缺点：
1. 链表每个节点之间的内存都是==不连续的==，意味着==**无法很好利用 CPU 缓存**==
2. 保存一个链表节点的值都需要一个链表节点结构头的分配，==**内存开销较大**==



---
# 压缩列表(ziplist)

压缩列表的最大特点，就是它被设计成一种==内存紧凑型==的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销  
但是，压缩列表的缺陷也是有的：
- 不能保存过多的元素，否则查询效率就会降低；
- 新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，甚至可能引发连锁更新的问题

## 压缩列表结构设计

压缩列表是 Redis 为了节约内存而开发的，它是==**由连续内存块组成的顺序型数据结构**==
![[ab0b44f557f8b5bc7acb3a53d43ebfcb.webp]]
- _**zlbytes**_，记录整个压缩列表占用对内存字节数；
- _**zltail**_，记录压缩列表「尾部」节点距离起始地址由多少字节，即==列表尾的偏移量==；
- _**zllen**_，记录压缩列表包含的节点数量；
- _**zlend**_，标记压缩列表的结束点，固定值 0xFF（十进制255） 

压缩列表节点（entry）的构成：
![[a3b1f6235cf0587115b21312fe60289c.webp]]

压缩列表节点包含三部分内容：
- _**prevlen**_，记录了「前一个节点」的长度，目的是为了实现从后向前遍历；
- _**encoding**_，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。
- _**data**_，记录了当前节点的实际数据，类型和长度都由 `encoding` 决定；

## 连锁更新
压缩列表除了查找复杂度高的问题，还有一个问题：
**压缩列表新增某个元素或修改某个元素时，==如果空间不不够，压缩列表占用的内存空间就需要重新分配==。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致==每个元素的空间都要重新分配==，造成访问压缩列表性能的下降**

## 压缩列表的缺陷
空间扩展操作也就是重新分配内存，因此**连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能**  
Redis 针对压缩列表在设计上的不足，在后来的版本中，新增设计了两种数据结构：==quicklist（Redis 3.2 引入）== 和 ==listpack（Redis 5.0 引入）==



----
# 哈希表
Redis的Hash对象的底层实现：压缩列表-->listpack/hashMap
哈希表优点在于，它**能以 O(1) 的复杂度快速查询数据**  
**Redis 采用了「链式哈希」来解决哈希冲突**  
## 哈希表结构设计
```c
typedef struct dictht {
    dictEntry **table;        //哈希表数组
    unsigned long size;       //哈希表大小
    unsigned long sizemask;   //哈希表大小掩码，用于计算索引值
    unsigned long used;       //该哈希表已有的节点数量
} dictht;
```

```c
typedef struct dictEntry {
    void *key;       //键值对中的键
    union {          //键值对中的值
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;    //指向下一个哈希表节点，形成链表
} dictEntry;
```

哈希表是一个数组（dictEntry **table )
数组的每个元素是一个指向「哈希表节点（dictEntry）」的指针

![[dc495ffeaa3c3d8cb2e12129b3423118.webp]]


## 链式哈希
实现的方式就是每个哈希表节点都有一个 ==next 指针==，用于指向下一个哈希表节点  
**被分配到同一个哈希桶上的多个节点可以用这个单项链表连接起来**
![[675c23857a36b2dab26ed2e6a7b94b5d.webp]]

链式哈希局限性也很明显，==随着链表长度的增加==，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询的时间复杂度是 O(n)  
要想解决这一问题，就需要进行 ==rehash，也就是对哈希表的大小进行扩展==  

## rehash
```c
typedef struct dict {
    …
    //两个Hash表，交替使用，用于rehash操作
    dictht ht[2]; 
    …
} dict;
```
![[2fedbc9cd4cb7236c302d695686dd478.webp]]

在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间  
随着数据逐步增多，触发了 rehash 操作，这个过程分为三步：
- 给「哈希表 2」 分配空间，==一般会比「哈希表 1」 大一倍==（两倍的意思）；
- 将「哈希表 1 」的数据==迁移==到「哈希表 2」 中；
- 迁移完成后，==「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」==，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。

![[cabce0ce7e320bc9d9b5bde947b6811b.webp]]

新问题：==**如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求**==

## 渐进式rehash

为了解决拷贝耗时的问题引进渐进式rehash，迁移工作变成多次迁移
步骤：
- 给「哈希表 2」 分配空间；
- **在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，==Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上**==；
- 随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作

## rehash触发条件（负载因子load factor）

![[85f597f7851b90d6c78bb0d8e39690fc.webp]]
1. load factor >= 1 && 没有执行RDB快照或进行AOF重写（Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令）
2. load factor >= 5，哈希冲突非常严重，强制rehash




---
# 整数集合(intset)

整数集合是 Set 对象的底层实现之一，当一个 Set 对象==只包含整数值元素，并且元素数量不大时==，就会使用整数集这个数据结构作为底层实现

## 整数集合结构设计
```c
typedef struct intset {
    uint32_t encoding;    //编码方式
    uint32_t length;      //集合包含的元素数量
    int8_t contents[];    //保存元素的数组，
} intset;
```
contents 数组的==真正类型==取决于 intset 结构体里的 encoding 属性的值

## 整数集合的升级操作
添加新元素到整数集合中，如果新元素的长度更长，需要按==新元素的类型扩展contents 数组的空间大小==，然后才能将新元素加入到整数集合里  
整数集合升级的过程不会重新分配一个新类型的数组，而是在==原本的数组上扩展空间==

![[e84b052381e240eeb8cc97d6b729968b.webp]]

### 整数集合升级有什么好处呢？

如果要让一个数组同时保存 int16_t、int32_t、int64_t 类型的元素，最简单做法就是直接使用 int64_t 类型的数组。不过这样的话，当如果元素都是 int16_t 类型的，就会造成==内存浪费==的情况，==整数集合升级就能避免这种情况==，只有我们需要将更长的元素添加到集合我们才升级  
因此，整数集合升级的好处是==**节省内存资源**==

### 整数集合支持降级操作吗？
==**不支持降级操作**==



---
# 跳表(skiplist)
Redis 只有 Zset 对象的底层实现用到了跳表，==跳表的优势是能支持平均 O(logN) 复杂度的节点查找==
zset维护了2个数据结构：skiplist/hashMap
```c
typedef struct zset {
    dict *dict;
    zskiplist *zsl;
} zset;
```
这样的好处：
1. 既能进行==高效的范围查询==
2. 也能进行==高效的单点查询==

Zset 对象在执行数据插入或是数据更新的过程中，会==依次在跳表和哈希表中插入或更新相应的数据，从而保证了跳表和哈希表中记录的信息一致==

## 跳表结构设计
**跳表是在链表基础上改进过来的，实现了==一种「多层」的有序链表==**

![[2ae0ed790c7e7403f215acb2bd82e884 1.webp]]

```c
typedef struct zskiplist {
    struct zskiplistNode *header, *tail;
    unsigned long length;
    int level;
} zskiplist;

typedef struct zskiplistNode {
    sds ele;         //Zset 对象的元素值
    double score;    //元素权重值
    struct zskiplistNode *backward;     //后向指针
    struct zskiplistLevel {             //节点的level数组，
        struct zskiplistNode *forward;  //保存每层上的前向指针
        unsigned long span;             //跨度
    } level[];
} zskiplistNode;
```

level 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示  
==跨度==时用来记录两个节点之间的距离

![[3层跳表-跨度.webp]]
==**跨度实际上是为了计算这个节点在跳表中的排位**==


## 跳表节点查询过程

1. 查找一个跳表节点的过程时，跳表会从头节点的==最高层开始==，逐一遍历每一层
2. 在遍历某一层的跳表节点时，会用跳表节点中的 ==SDS 类型的元素和元素的权重==来进行判断
- ==当前节点的权重 < 要查找的权重时==，跳表就会访问该层上的下一个节点
- ==当前节点的权重 == 要查找的权重时 && 当前节点的 SDS 类型数据 < 要查找的数据==时，跳表就会访问该层上的下一个节点
- ==前两个都不满足 or 下一个节点为空==，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找  

![[3层跳表-跨度.drawio.webp]]
> [!example] 如果要查找「元素：abcd，权重：4」的节点，查找的过程是这样的：
> 1. 先从头节点的最高层开始，L2 指向了「元素：abc，权重：3」节点，==这个节点的权重比要查找节点的小，所以要访问该层上的下一个节点；==
> 2. 但是该层的下一个节点是==空节点==（ leve[2]指向的是空节点），于是就会跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[1];
> 3. 「元素：abc，权重：3」节点的 leve[1] 的下一个指针指向了「元素：abcde，权重：4」的节点，然后将其和要查找的节点比较。虽然「元素：abcde，权重：4」的节点的权重和要查找的权重相同，==但是当前节点的 SDS 类型数据「大于」要查找的数据==，所以会继续跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[0]；
> 4. 「元素：abc，权重：3」节点的 leve[0] 的下一个指针指向了「元素：abcd，权重：4」的节点，该节点正是要查找的节点，查询结束。


## 跳表节点层数设置

跳表的==相邻两层的节点数量的比例==会影响跳表的查询性能
第二层的节点数量只有 1 个，而第一层的节点数量有 6 个

![[2802786ab4f52c1e248904e5cef33a74.webp]]

==**跳表的相邻两层的节点数量最理想的比例是2:1  
查找复杂度可以降低到 O(logN)**==

![[cdc14698f629c74bf5a239cc8a611aeb.webp]]

> 那怎样才能维持相邻两层的节点数量的比例为 2 : 1 呢？

如果采用新增节点或者删除节点时，来调整跳表节点以维持比例的方法的话，会带来额外的开销。Redis 则采用一种巧妙的方法是，==**跳表在创建节点的时候，随机生成每个节点的层数**==，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况

具体的做法是，==**跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数**==

## 为什么用跳表而不用平衡树？

一个常见的面试题：==为什么 Zset 的实现用跳表而不用平衡树（如 AVL树、红黑树等）？==
1. **从内存占用上来比较，跳表比平衡树更灵活一些**。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势
2. **在做范围查找的时候，跳表比平衡树操作要简单**。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。
3. **从算法实现难度上来比较，跳表比平衡树要简单得多**。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。



---
# quickList

==quicklist = 双向链表 + 压缩链表==
## quicklist结构设计
```c
typedef struct quicklist {
    quicklistNode *head;    //quicklist的链表头
    quicklistNode *tail;    //quicklist的链表尾
    unsigned long count;    //所有压缩列表中的总元素个数
    unsigned long len;      //quicklistNodes的个数
    ...
} quicklist;


typedef struct quicklistNode {
    struct quicklistNode *prev;     //前一个quicklistNode
    struct quicklistNode *next;     //后一个quicklistNode
    unsigned char *zl;              //quicklistNode指向的压缩列表   
    unsigned int sz;                //压缩列表的的字节大小
    unsigned int count : 16;        //ziplist中的元素个数 
    ....
} quicklistNode;
```

![[f46cbe347f65ded522f1cc3fd8dba549.webp]]


在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点,而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构  
quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并==没有完全解决连锁更新的问题==



---
# listpack

==压缩列表连锁更新的问题，来源于它的结构设计==，所以要想彻底解决这个问题，需要设计一个新的数据结构  
## listpack结构设计

![[4d2dc376b5fd68dae70d9284ae82b73a.webp]]
![[c5fb0a602d4caaca37ff0357f05b0abf.webp]]
- encoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；
- data，实际存放的数据；
- len，encoding+data的总长度  

**listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，==当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，==从而避免了压缩列表的连锁更新问题**

## 压缩列表的entry为什么要保存prevlen呢？listpack改成len之后不会影响功能吗

### ziplist结构：
![[a3b1f6235cf0587115b21312fe60289c.webp]]

### listpack结构:
![[c5fb0a602d4caaca37ff0357f05b0abf.webp]]

压缩列表的 entry 保存 prevlen 是==为了实现节点从后往前遍历，知道前一个节点的长度，就可以计算前一个节点的偏移量==  

listpack 一样可以支持从后往前遍历的。详细的算法可以看：https://github.com/antirez/listpack/blob/master/listpack.c 里的lpDecodeBacklen函数  
==lpDecodeBacklen 函数==就可以从==当前列表项起始位置的指针开始，向左逐个字节解析==，得到前一项的 entry-len 值