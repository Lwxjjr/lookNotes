![[提纲.webp]]

# undo log
我们在执行一条“增删改”的语句时候，MySQL 会**隐式开启事务**来执行“增删改”语句的，执行完就自动提交事务的，可以及时在数据库表看到“增删改”的结果了
执行一条语句是否自动提交事务，是由 `autocommit` 参数决定的，默认是开启
> [!考虑]
> 一个事务在执行过程中，在还没有提交事务之前，如果 MySQL 发生了崩溃，要怎么回滚到事务之前的数据呢？

**undo log（回滚日志），它保证了事务的 ACID 特性中的原子性（Atomicity）**
undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚
对于不同的操作：
- 插入数据，把记录的主键值记下来，回滚时把对应主键值的记录删除
- 删除数据，把这条记录的内容记下来，回滚时把这些内容组成的记录插入到表中
- 更新记录，把更新的旧值记录下来，回滚时把这些列更新为旧值

一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：
- 通过 trx_id 可以知道该记录是被哪个事务修改的
- 通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链

![[版本链.webp]]

## undo log 作用
- **实现事务回滚，保障事务的原子性**
- **`ReadView + undo log` 实现 `MVCC`**(`MVCC`就是通过`ReadView`和`undo log`去实现并发读写，确保事务隔离和数据一致性的数据库并发控制技术)
	- `undo log` 为每条记录保存多份历史数据
	- MySQL 在执行快照读（普通 select 语句），会根据事务的 `Read View` 里的信息，顺着 `undo log` 的版本链找到满足其可见性的记录

> [!Tip]
> `undo log`刷盘
> `undo log` 和数据页的刷盘策略是一样的，都需要通过 `redo log` 保证持久化
> `buffer pool` 中有 `undo` 页，对 `undo` 页的修改也都会记录到 `redo log`


---
# Buffer Pool
`MySQL`的数据记录在磁盘中，们要更新一条记录的时候，得先要从磁盘读取该记录，然后在内存中修改这条记录
`Innodb` 存储引擎设计了一个**缓冲池（Buffer Pool）**，来提高数据库的读写性能

有了 `Buffer Pool` 后：
- 当读取数据时，如果数据存在于 `Buffer Pool` 中，客户端就会直接读取 `Buffer Pool` 中的数据，否则再去磁盘中读取。
- 当修改数据时，如果数据存在于 `Buffer Pool` 中，那直接修改 `Buffer Pool` 中数据所在的页，==然后将其页设置为脏页==（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘

InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB
==在 MySQL 启动的时候==，**InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的`16KB`的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页**
此时这些缓存页==都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中==

> [!Tip]
> 所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，申请物理内存，接着将虚拟地址和物理地址建立映射关系

![[bufferpool内容.drawio.webp]]


---
# redo log
`redo log`是==物理日志==，记录某个数据页做了什么修改
事务提交时，只需要把`redo log`持久化到磁盘即可，不需要等到将缓存在`Buffer Pool`里的脏页数据持久化磁盘
当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化

`Buffer Pool`可以提高读写效率，但是`Buffer Pool`基于内存，但是万一断电重启，还没来得及落盘的脏页数据就会丢失
为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，==InnoDB 引擎就会先更新内存（同时标记为脏页）==，然后将本次对这个页的修改以 redo log 的形式记录下来，**这个时候更新就算完成了**
后续，InnoDB 引擎会在适当的时候，由==后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里==，这就是 ==**WAL （Write-Ahead Logging）技术**==

![[wal.webp]]


> [!Tip] redo log 和 undo log 区别
 
- redo log 记录了此次事务「**修改后**」的数据状态，记录的是更新**之后**的值，**主要用于事务崩溃恢复，保证事务的持久性**。
- undo log 记录了此次事务「**修改前**」的数据状态，记录的是更新**之前**的值，**主要用于事务回滚，保证事务的原子性**

> [!Tip] redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举

写入 redo log 的方式使用了追加操作， 所以磁盘操作是==**顺序写**==
写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是==**随机写**==
因此 redo log 写入磁盘的开销更小
==WAL技术优点：**MySQL 的写操作从磁盘的「随机写」变成了「顺序写」**，提升语句的执行性能==
- **实现事务的持久性，让 MySQL 有 crash-safe 的能力**，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；
- **将写操作从「随机写」变成了「顺序写」**，提升 MySQL 写入磁盘的性能

> [!Tip] 产生的 redo log 是直接写入磁盘的吗？

执行一个事务的过程中，产生的 redo log 也不是==直接写入磁盘的==，==因为这样会产生大量的 I/O 操作，而且磁盘的运行速度远慢于内存==
redo log 也有自己的缓存—— ==**redo log buffer**==
每当产生一条 redo log 时，会先写入到 redo log buffer
redo log buffer 默认大小 16 MB，可以通过 `innodb_log_Buffer_size` 参数动态的调整大小，==增大它的大小可以让 MySQL 处理「大事务」是不必写入磁盘，进而提升写 IO 性能==

## redo log 刷盘
缓存在 redo log buffer 里的 redo log 还是在内存中，它什么时候刷新到磁盘？
主要有下面几个时机：
- ==MySQL 正常关闭时==
- 当 redo log buffer 中记录的==写入量==大于 redo log buffer ==内存空间的一半时==，会触发落盘
- ==InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘==
- ==每次事务提交时==都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 `innodb_flush_log_at_trx_commit` 参数控制）

> [!Tip] innodb_flush_log_at_trx_commit
> - 0，每次事务提交时，将 redo log 留在 redo log buffer 中，==事务提交时不会主动触发写入磁盘的操作==
> - 1，每次事务提交时，将缓存在 redo log buffer里的 redo log ==直接持久到磁盘==，这样可以保证 MySQL 异常重启之后数据不会丢失
> - 2，每次事务提交时，将缓存在 redo log buffer里的 redo log ==写入 redo log 文件==，意味着写入了操作系统的文件系统 Page CaChe

![[innodb_flush_log_at_trx_commit.drawio.webp]]

## redo log 文件写满了怎么办
默认情况下，InnoDB 存储引擎有 1 个重做日志文件组(redo log Group）
由 2 个`redo log`文件组成：
- `ib_logfile0` 
- `ib_logfile1`

![[重做日志文件组.drawio.webp]]

在重做日志组中，==每个 redo log File 的大小是固定且一致的==，假设每个 redo log File 设置的上限是 1 GB，那么总共就可以记录 2GB 的操作

> [!Tip]
> redo log 是为了防止 Buffer Pool 中的脏页丢失而设计的，那么如果随着系统运行，==Buffer Pool 的脏页刷新到了磁盘中==，那么 redo log 对应的记录也就没用了，这时候我们==擦除这些旧记录，以腾出空间记录新的更新更新操作==

重做日志文件组是以==**循环写**==的方式工作的，从头开始写，写到末尾就又回到开头，相当于一个环形
- 红色部分：用来记录新的更新操作
- 蓝色部分：待落盘的脏数据页记录

write pos 追上了 checkpoint，意味着：**redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞**，此时**会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）**
![[checkpoint.webp]]


---
# bin log
`undo log` 和 `redo log` 这两个日志都是 `Innodb` 存储引擎生成的
`MySQL` 在完成一条更新操作后，`Server` 层还会生成一条 `binlog`，等之后事务提交的时候，会将该事物执行过程中产生的所有 `binlog` 统一写 入 `binlog` 文件

`binlog` 文件是记录了所有==数据库表结构变更和表数据修改==的日志，不会记录查询类的操作，比如 `SELECT` 和 `SHOW` 操作
==`bin log`可以用于恢复数据库的数据，采用追加写的方式，因为它保存的是全量的日志==

## 主从复制
MySQL 的主从复制依赖于 `binlog`
复制的过程就是将 `binlog` 中的数据从主库传输到从库上

![[主从复制过程.drawio.webp]]

MySQL 集群的主从复制过程梳理成 3 个阶段：
- **写入 Binlog**：主库写 binlog 日志，提交事务，并更新本地存储数据
- **同步 Binlog**：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中
- **回放 Binlog**：回放 binlog，并更新存储引擎中的数据

> [!warning] 从库不是越多越好
> 从库数量增加，从库连接上来的 I/O 线程也比较多，主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽

> [!Tip] 主从复制模型
> - **同步模型**：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。实际项目中无法使用，一来性能很差，二来可用性很差，但凡有一个数据库出现问题，都会影响业务
> - **异步模型（默认）**：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。
> - **半同步复制**：事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行

## bin log 刷盘
事务执行过程中，先把日志写到 `binlog cache`
事务提交的时候，再把 `binlog cache` 写到 `binlog` 文件中
一个事务的 binlog 是不能被拆开的，因此无论这个事务有多大（比如有很多条语句），也要保证一次性写入
MySQL 给每个线程分配了一片内存用于缓冲 binlog ，该内存叫 binlog cache，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。==如果超过了这个参数规定的大小，就要暂存到磁盘==


---
# update 语句执行过程
> [!example] 
>  具体更新一条记录 `UPDATE t_user SET name = 'xiaolin' WHERE id = 1`




