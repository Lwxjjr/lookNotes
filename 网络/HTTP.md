# 应用层协议
HTTP、HTTPS、CDN、DNS、FTP

| 协议    | 主要用途 | 端口  | 特点               |
| ----- | ---- | --- | ---------------- |
| HTTP  | 网页浏览 | 80  | 明文传输             |
| HTTPS | 安全网页 | 443 | 加密传输             |
| DNS   | 域名解析 | 53  | 域名→IP转换          |
| CDN   | 内容加速 | 多种  | 将内容缓存到全球各地的边缘服务器 |
| FTP   | 文件传输 | 21  | 在客户端和服务器间传输文件    |

超文本传输协议，HyperText Transfer Protocol
![[Pasted image 20250403110818.png|400]]  
==**HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」**==
> [!info] 这里的两点之间可以是 服务器 <--> 服务器，也可以是服务器 <--> 浏览器

---
# 从输入URL到页面展示中发生了什么（打开一个网页，整个过程会使用哪些协议？）

![[Pasted image 20250508201451.jpg]]

> [!warning] 有一个错误需要注意：是 OSPF 不是 OPSF。 OSPF（Open Shortest Path First，ospf）开放最短路径优先协议, 是由 Internet 工程任务组开发的路由选择协议

总体来说分为以下几个步骤:
1. 在浏览器中输入指定网页的 URL，==解析URL==（协议+//+Web服务器+路径名）
2. ==浏览器通过 [[IP#DNS]] 协议，获取域名对应的 IP 地址==。
3. 浏览器根据 IP 地址和端口号，向目标服务器发起一个 ==TCP 连接请求==。[[TCP握手#既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？]]
4. 浏览器在 TCP 连接上，向服务器发送一个 ==HTTP 请求报文，请求获取网页的内容==。
5. 服务器收到 HTTP 请求报文后，处理请求，并返回 HTTP 响应报文给浏览器。
6. 浏览器收到 HTTP 响应报文后，解析响应体中的 HTML 代码，渲染网页的结构和样式，同时根据 HTML 中的其他资源的 URL（如图片、CSS、JS 等），再次发起 HTTP 请求，获取这些资源的内容，直到网页完全加载显示。
7. 浏览器在不需要和服务器通信时，可以主动关闭 TCP 连接，或者等待服务器的关闭请求。


---
# 封装好的数据包发送

![[21.webp]]

## 网卡
==网络包只是存放在内存中的一串二进制数字信息==，没有办法直接发送给对方
**网卡**：需要将**数字信息转换为电信号**，才能在网线上传输
要控制网卡还需要靠**网卡驱动程序**
网卡驱动获取网络包之后，会将其**复制**到网卡内的缓存区中，接着会在其**开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列**
![[数据包.drawio.webp]]

> [!info] 最后网卡会将包转为电信号，通过网线发送出去

---
## 交换机
> [!info] 在子网中

交换机的设计是将网络包**原样**转发到目的地。交换机工作在 MAC 层，也称为**二层网络设备**
**交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口**
如果找不到，则转发到除了源端口之外的所有端口上

![[23 1.webp]]
> [!info] 数据包通过交换机转发抵达了路由器，离开了子网


---
## 路由器
> [!info] 网络包经过交换机之后，现在到达了**路由器**，并在此被转发到下一个路由器或目标设备

> [!tip] 路由器和交换机
> - 因为**路由器**是基于 IP 设计的，俗称**三层**网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；
> - 而**交换机**是基于以太网设计的，俗称**二层**网络设备，交换机的端口不具有 MAC 地址

路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的

当转发包时，首先路由器端口会接收发给自己的以太网包，然后==**路由表**查询转发目标==，再由相应的端口作为发送方将以太网包发送出去
完成包接收操作之后，==路由器就会**去掉**包开头的 MAC 头部==，因为**MAC 头部的作用就是将包送达路由器**，接下来，路由器会根据 MAC 头部后方的 `IP` 头部中的内容进行包的转发操作


---
# HTTP报文
![[1721710466863-78bf586d-a25c-4fe4-bf27-5dd576b998c8.webp]]

分请求报文和响应报文来说明。

**请求报文：**
- 请求行：包含请求方法、请求目标（URL或URI）和HTTP协议版本。
- 请求头部：包含关于请求的附加信息，如Host、User-Agent、Content-Type等。
- 空行：请求头部和请求体之间用空行分隔。
- 请求体：可选，包含请求的数据，通常用于POST请求等需要传输数据的情况。

**响应报文：**
- 状态行：包含HTTP协议版本、状态码和状态信息。
- 响应头部：包含关于响应的附加信息，如Content-Type、Content-Length等。
- 空行：响应头部和响应体之间用空行分隔。
- 响应体：包含响应的数据，通常是服务器返回的HTML、JSON等内容。
---
# 状态码
![[6-五大类HTTP状态码.webp]]
### 常用状态码
1. 2xx
	- 200 OK：正常，服务器返回响应头有body数据
	- 204 No Content：正常，响应头没有body数据
	- 206 Partial Content：HTTP分块下载/断点续传，响应返回的body数据不是资源的全部
2. 3xx
	- 301 Moved Permanently：永久重定向
	- 302 Found：临时重定向
		- 301，302都会在响应头里面使用Location，指明后续要跳转的URL，浏览器自动跳转
	- 304 Not Modified：不具有跳转的含义，表示资源未修改
3. 4xx
	- 400 Bad Request：表示客户端请求的报文有错误，但只是个笼统的错误。 
	- 403 Forbidden：表示服务器禁止访问资源，并不是客户端的请求出错。 
	- 404 Not Found：表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端
4. 5xx
	- 500 Internal Server Error：笼统错误码，服务器发生了什么错误，我们不知道
	- 501 Not Implemented：客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思
	- 502 Bad Gateway：服务器作为网关或代理时返回的错误码，示服务器自身工作正常，访问后端服务器发生了错误
	- 503 Service Unavailable：服务器当前很忙，暂时无法响应客户端


---
# HTTP常见字段
1. Host：客户端发送请求时，==指定服务器的域名==（www.A.com)
2. Content-Length：服务器在返回数据时，表明==本次回应的数据长度==（拆包）
> [!tip] 这两个方式都是为了解决"粘包"的问题
>  HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界  
> 通过 Content-Length 字段作为 HTTP body 的边界  

3. Connection：客户端要求服务器==使用「HTTP 长连接」机制==
4. Content-Type：服务器回应时，告诉客户端，==本次数据是什么格式==
5. Content-Encoding：服务器返回的数据使用了什么==压缩格式==


---
# HTTP缓存
对于一些重复性的 HTTP 请求，我们可以把这对「请求-响应」的数据都==缓存在本地==，下次就直接读取本地的数据，不必在通过网络获取服务器的响应了
## 强制缓存（from disk cache）
只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定==是否使用缓存的主动性在于浏览器这边==
利用两个HTTP响应头部字段实现（Response Header）：
1. Cache-Control：相对时间（优先级更高）
2. ExPires：绝对时间

流程：
1. 浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小
2. 浏览器再次请求访问服务器中的该资源时，会先**通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，如果没有，则使用该缓存，否则重新请求服务器
3. 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control

## 协商缓存
协商缓存就是与服务端协商之后，通过协商结果来判断==是否使用本地缓存==  
基于2种头部实现：
1. 请求头部中的 `If-Modified-Since` + 响应头部中的 `Last-Modified`
	1. Last-Modified：标示这个响应资源的最后修改时间
	2. If-Modified-Since：资源过期，发现响应头部有Last-Modified，再次发起请求的时候带上Last-Modified的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified）
		1. 如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK
		2. 最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存
2. 请求头部中的 `If-None-Match`  + 响应头部中的 `ETag`'
	1. ETag：唯一标识响应资源
	2. If-No-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值服，务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200

==第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的==  

---
# GET/POST
- **GET 的语义是从服务器获取指定的资源**，请求的参数位置一般是写在 URL 中，参数只允许 ASCII 字符，而且 URL 的长度是有限制的
- **POST 的语义是根据请求负荷（报文body）对指定的资源做出处理**，请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据

从语义角度：
- **GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的
- **POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的
---
# HTTP/1.1
## HTTP最突出的优点：
1. ==简单==，基本报文格式：`header + body`，头部信息也是 `key-value` 的形式
2. ==灵活、易于扩展==，HTTP是工作在应用层，下层可以随意变化
3. ==应用广泛和跨平台==
## HTTP/1.1的双刃剑
1. ==无状态==（可以引入cookie）：
	1. 好处：服务器不会记忆HTTP的状态，不需要额外的资源来记录状态信息
	2. 坏处：没记忆功能，关联性的操作麻烦，缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大
2. ==明文传输==：
	1. 好处：方便抓包
	2. 坏处：信息裸奔，信息全部都暴露了
3. ==不安全==（HTTPS解决，引入SSL/TLS层）：
	1. 通信使用明文（不加密），内容可能会被窃听
	2. 不验证通信方的身份，因此有可能遭遇伪装
	3. 无法证明报文的完整性，所以有可能已遭篡改
## HTTP/1.1性能
HTTP协议是基于==TCP/IP==，使用了==请求-应答==的通信模式  
1. ==长连接==：减少TCP连接的重复建立和断开所造成的额外开销，特点是：==只要任意一段没有明确提出断开连接==，则保持TCP连接状态，如果某个 HTTP 长连接超过一定时间没有任何数据交互，服务端就会主动断开这个连接
2. ==管道网络传输（pipeline）==：同一个TCP连接中，客户端可以发起多个请求，但是服务器必须按照接收请求的顺序发送对这些管道化请求的响应，==所以HTTP/1.1管道解决了请求的队头阻塞，没有解决响应的对头阻塞==
3. ==队头阻塞==：因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据

> [!info] 长连接
> **Keep-Alive 使用同一个 TCP 连接和接收多个 HTTP 请求/应答**
> **特点是只要任意一端没有明确提出断开连接，则保持 TCP 连接状态**
> 目的是为了减少创建/关闭多个TCP连接的开销
> HTTP 协议采用的是「请求-应答」的模式
> HTTP 是基于 TCP 传输协议实现的，需要先建立 TCP 连接
> 短连接：建立 TCP -> 请求资源 -> 响应资源 -> 释放连接

## 断点传输
实现断点续传的功能，需要客户端记录下当前的下载进度，并在需要续传的时候通知服务端本次需要下载的内容片段
一个最简单的断点续传流：
1. 客户端开始下载一个1024K的文件，服务端发送Accept-Ranges: bytes来告诉客户端，其支持带Range的请求
2. 假如客户端下载了其中512K时候网络突然断开了，过了一会网络可以了，客户端再下载时候，需要在HTTP头中申明本次需要续传的片段：Range:bytes=512000-这个头通知服务端从文件的512K位置开始传输文件，直到文件内容结束
3. 服务端收到断点续传请求，从文件的512K位置开始传输，并且在HTTP头中增加：Content-Range:bytes 512000-/1024000,Content-Length: 512000。并且此时服务端返回的HTTP状态码应该是206 Partial Content。如果客户端传递过来的Range超过资源的大小,则响应416 Requested Range Not Satisfiable

断点传输的4个 HTTP 头：
1. Range
2. Content-Range头
3. Accept-Ranges头
4. Content-Length头

- Accept-Ranges: bytes：这个值声明了可被接受的每一个范围请求, 大多数情况下是字节数 bytes
- Range: bytes=开始位置-结束位置：Range是浏览器告知服务器所需分部分内容范围的消息头。
---
# HTTPS
## HTTP && HTTPS
1. 加密
	- HTTP信息是明文传输，存在安全风险的问题。
	- HTTPS在TCP和HTTP网络层加入了SSL/TLS安全协议，使得报文能够加密传输
2. 连接
	- HTTP建立TCP三次握手后便可以开始HTTP的报文传输
	- HTTP建立TCP三次握手后还需要SSL/TLS的握手过程
3. 端口
	- HTTP默认：80
	- HTTPS默认：443
4. HTTPS协议需要向CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的

## HTTPS解决了什么问题？
HTTP是明文传输，存在三个风险：
1. 窃听风险
2. 篡改风险
3. 冒充风险

HTTPS在HTTP和TCP层中加入了SSL/TLS协议：
1. 信息加密：交互信息无法被窃取
2. 校验机制：无法篡改通信内容，篡改了就不能正常显示
3. 身份证书：证明淘宝是真的淘宝网

### HTTPS是怎么解决这3个风险？
1. 窃听风险：==混合加密==保证消息机密性
2. 篡改风险：==摘要算法==实现完整性，指纹用于校验数据完整性
3. 冒充风险：服务器公钥放入==数字证书==

#### 1. 混合加密
1. 在通信建立前采用==非对称加密==的方式交换「会话秘钥」
2. 在通信过程中全部使用==对称加密==的「会话秘钥」的方式加密明文数据  

采用「混合加密」的方式的原因：
- **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
- **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

#### 2. 摘要算法 + 数字签名
传输前对内容Hash计算指纹，（内容 + 指纹）一同传输给对方  
对方收到后，对内容Hash计算指纹，比较来判断是否篡改  
==这样可以确保内容不会被篡改，但是不能保证（内容 + 指纹）不会被中间人替换，缺少证明客户端收到的信息是否来源于服务端的证明==  
为了避免着这种情况，计算机会使用==非对称加密算法==来解决（公钥 + 私钥）
1. **公钥加密，私钥解密**：==为了保证内容传输的安全==，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容
2. **私钥加密，公钥解密**：==为了保证消息不会被冒充==，因为被私钥加密的内容，使用公钥才能解密，可以说明这个密文一定来自于私钥持有者

> [!tip ] 数字签名算法
> 非对称加密的用途主要在于==「私钥加密，公钥解密」==，来确认消息的身份，对内容的哈希值加密

#### 3. 数字证书
虽然有哈希算法保证消息的完整性，数字签名保证消息的来源可靠性，但是缺少身份验证的环节，公私钥可以被伪造
![[22-数字证书工作流程.webp]]


---
# HTTPS建立连接
SSL/TLS协议基本流程：
1. 客户端向服务端索要并验证服务器的公钥
2. 双方协商生成【会话密钥】
3. 双方采用【会话密钥】进行加密通信

TLS握手涉及4次通信，常见的密钥交换算法有：
1. RSA算法
2. ECDHE算法

## TLS协议建立过程
### 1. ClientHello
客户端向服务端发起加密通信请求（ClientHello），发送信息：
1. 客户端支持的TLS协议版本，如TLS1.2版本
2. 客户端生成的随机数（Client Random）
3. 客户端支持的密码套件列表，如RSA加密算法
### 2. ServerHello
服务器收到客户端请求后，向客户端发出响应（ServerHello），回应内容：
1. 确认TLS协议版本，如果浏览器不支持，则关闭加密通信
2. 服务器生成的随机数（Server Random）
3. 确认的密码套件
4. 服务器的数字证书
### 3. 客户端回应
通过CA公钥，确认服务器的数字证书真实性  
![[证书的校验.webp]]
CA颁发数字证书过程：
1. CA把持有者的公钥、用途、颁发者、有效时间等信息打包，会其做Hash计算
2. CA使用自己的私钥加密，生成 Certificate Signature，即对证书签名
3. 把 Certificate Signature 添加在文件证书上，形成数字证书

客户端从数字证书中取出服务器的公钥，用它加密报文，发送信息：
1. 随机数（pre-master key），被服务器公钥加密
2. 加密通信算法改变，使用【会话密钥】加密通信
3. 客户端握手结束通知
### 4. 服务端回应
服务器收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法，计算出本次通信的【会话秘钥】，发送信息：
1. 加密通信算法改变，使用【会话密钥】加密通信
2. 服务端握手结束通知

---
# HTTPS一定安全吗？
> [!example]
> 客户端通过浏览器向服务端发起 HTTPS 请求时，被「假基站」转发到了一个「中间人服务器」，于是客户端是和「中间人服务器」完成了 TLS 握手，然后这个「中间人服务器」再与真正的服务端完成 TLS 握手

![[https中间人.drawio.webp]]

从客户端的角度看，其实并不知道网络中存在中间人服务器这个角色。那么中间人就可以解开浏览器发起的 HTTPS 请求里的数据，也可以解开服务端响应给浏览器的 HTTPS 响应数据  
==前提是用户点击接受了中间人服务器的证书==  
中间人服务器与客户端在 TLS 握手过程中，==实际上发送了自己伪造的证书给浏览器==，而这个伪造的证书是==能被浏览器（客户端）识别出是非法的==，于是就会提醒用户该证书存在问题  

![[证书安全提示.webp]]

所以：
1. 用户坚持访问，信任了中间人服务器的证书
2. 电脑中毒，被恶意导入了中间人的根证书，验证中间人的证书时，因为操作系统信任了中间人的根证书，等同于中间人的证书是合法的，这种情况下，浏览器就不会弹出证书存在问题的风险提醒了

---
# 怎么避免被中间人抓取数据
一般我们的HTTPS是单向认证，客户端只会验证服务端的身份，但是服务端不会验证客户端的身份  
我们要保证自己电脑的安全，不要==被病毒乘虚而入==，而且也==不要点击任何证书非法的网站==，这样 HTTPS 数据就不会被中间人截取到了  
还可以通过==双向认证==的方式来避免这个问题  

---
# HTTP演变

## HTTP1.1相比HTTP/1.0
优点：
1. ==长连接==改进短连接造成的性能开销
2. 支持管道（pipeline）网络传输，==只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去==，可以减少整体的响应时间  

性能瓶颈：
1. ==请求/响应头部（Header）未经压缩就发送==，首部信息越多延迟越大。只能压缩Body
2. 发送冗长的首部。==每次互相发送相同的首部造成的浪费较多==
3. ==队头阻塞==
4. ==没有请求优先级控制==
5. 请求只能从客户端开始，==服务器只能被动响应==

## HTTP/2相比HTTP/1.1
### 改进：
1. 头部压缩
2. 二进制格式
3. 并发传输
4. 服务器主动推送资源

#### 1. 头部压缩
如果你同时发出多个请求，他们的头是一样的或是相似的，那么，==协议会帮你**消除重复的部分**==，即 `HPACK` 算法，==服务器和客户端同时维护一张头信息表==，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了
#### 2. 二进制格式
HTTP1.1采用纯文本形式的报文  
HTTP2采用二进制格式，头信息和数据体都是二进制，并且统称为==帧（frame）==  
**头信息帧（Headers Frame）和数据帧（Data Frame）**  

![[二进制帧.webp]]

#### 3. 并发传输
HTTP/1.1 的实现是基于请求-响应模型的，在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了**队头阻塞**的问题  
HTTP/引入 Stream 概念，多个 Stream 复用在一条 TCP 连接
![[stream.webp]]
Message对应HTTP/1中的请求或响应，由HTTP头部和包体构成  
Message 里包含一条或者多个 Frame  
==针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接受端可以通过 Stream ID 有序组装成 HTTP 消息==，不同的 Stream Frame 可以乱序发送，因此可以并发不同的 Stream

#### 4. 服务器推送
服务器不再是被动地响应，可以==主动向客户端发送消息==  
HTTP/2中，客户端在访问HTML时，服务器可以主动推送CSS文件，减少消息传递的次数  

![[push.webp]]

---
### HTTP/2的缺陷
HTTP/2存在==TCP"队头阻塞"问题==  
**HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，==TCP 层必须保证收到的字节数据是完整且连续的==，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题**    
![[http2阻塞.webp]]

所以，==**一旦发生丢包现象，就会触发TCP重传机制**==，这样在一个TCP连接中的所有的HTTP请求都必须等待这个丢失的包被重传回来  

---
## HTTP/3
1. HTTP/1.1引入了管道（pipeline）机制，解决了请求的队头阻塞问题，但是==没有解决响应的队头阻塞问题，因为服务端需要按顺序响应收到的请求==
2. HTTP/2通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞，==但是一旦发生丢包，就会阻塞所有的HTTP请求==

HTTP/2队头阻塞的问题是因为TCP，所以==**HTTP/3把HTTP下层的协议改成了UD**P==  
![[27-HTTP3.webp]]

UDP发送不管顺序，不管丢包，不会出现HTTP/2队头阻塞的问题，虽然UDP是不可靠传输，但是基于 UDP 的 ==QUIC== 协议可以实现类似 TCP 的可靠传输
> [!question] UDP不可靠的原因：
> 1. 无连接
> 2. 无保证的数据交付
> 3. 无序送达
> 4. 无流量控制/无拥塞控制
> 5. 缺乏重传
> 6. 有限的错误检测


### UDP对比
1. 低延迟：因为是无连接的协议，不需要再数据传输之前建立连接，因此可以减少传输时延
2. 简单快速：比TCP更简单，没有TCP的连接管理和流量控制机制，传输效率更高
3. 轻量级：UDP头部较小，占用较少的网络资源，对于小型请求和响应来说更加轻量级
### QUIC协议
QUIC 有以下 3 个特点。
1. 无队头阻塞
2. 更快的连接建立
3. 连接迁移
#### 1. 无队头阻塞
==**当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题**==  
QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响  
![[quic无阻塞.webp]]
#### 2. 更快的连接建立
对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，很难把它们合并在一起，需要分批次握手  
HTTP/3 传输需要 QUIC 协议握手，握手需要 `1RTT`  
握手的目的：确认双方的【连接ID】，连接迁移就是基于 ID 来实现的  
 HTTP/3 的 QUIC 协议并不是与 TLS 分层，
1. ==QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”==  
2. QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商  

![[28-HTTP3交互次数.webp]]甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果

#### 3. 数据迁移
==基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接== 

![[format,png-20230309231026577.webp]]

==**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**==  
建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的  

QUIC 协议没有用四元组的方式来“绑定”连接，而是==通过**连接 ID** 来标记通信的两个端点==   
只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能  

==QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用协议==