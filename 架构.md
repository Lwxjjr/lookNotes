```go
gin-pathway/
├── cmd/                     # 应用启动入口
│   └── main.go              # 主程序入口
├── configs/                 # 配置文件存放目录
│   └── config.yaml          # 示例配置文件
├── docs/                    # 文档文件，如 Swagger api 等
├── internal/                # 内部包，存放核心业务逻辑
│   ├── api/                 # 版本路由
│   ├── app/                 # 包括应用程序启动、初始化等逻辑
│   ├── controller/          # HTTP 请求处理函数
│   ├── middleware/          # 中间件
│   ├── model/               # 数据模型定义
│   ├── repository/          # 数据访问层
│   ├── service/             # 业务逻辑层
│   └── utils/               # 工具函数
├── pkg/                     # 第三方依赖或公共工具包
├── scripts/                 # 脚本文件，如项目部署脚本等
├── tests/                   # 单元测试文件
├── .env                     # 环境变量文件
├── go.mod                   # Go 模块管理文件
├── go.sum                   # Go 模块依赖校验文件
└── README.md                # 项目说明文档
```

1. `configs` 目录包含配置结构体和 YAML 配置文件，支持数据库连接参数、JWT 密钥等配置
2. `model` 结构体通过 GORM 标签与 MySQL 表字段映射
3. `repository`实现了与 MySQL 的交互，封装了完整的 CRUD 操作
4. `service`实现核心业务逻辑
5. `controller`处理 HTTP 请求，负责参数绑定、调用服务层并返回响应
6. `api` 定义 API 路由



### 方向二：时序数据优化

这个方向是把 Bitcask 从一个通用的 KV 存储，改造成一个对**时间序列数据**（Time-Series Data）更友好的专用存储引擎。

- **课题简介:**  
    本项目旨在针对时序数据（如物联网传感器读数、系统监控指标）的特性，对 Bitcask 存储模型进行深度优化。通过引入基于时间窗口的数据文件切分策略，将数据按时间顺序物理组织，从而极大地提升时间范围查询的性能。同时，研究并实现数据降采样（Downsampling）机制，在数据合并过程中对历史数据进行聚合，以显著降低长期存储成本。
    
- **研究方向与实现步骤:**
    
    1. **时间窗口文件切分 (Time-Window Compaction):**
        
        - 修改 Bitcask 的文件管理策略。不再是当文件达到固定大小时才切换，而是根据时间来创建新的活跃文件。例如，每小时或每天创建一个新的数据文件（文件名可以包含时间戳，如 20251015.data）。
            
        - 这样做最大的好处是：数据在物理上就是按时间排序的。一个 “查询过去一小时数据” 的请求，只需要打开最近一两个数据文件即可，无需扫描全量数据。
            
    2. **实现时间范围查询 API:**
        
        - 设计新的 API，例如 GetRange(startTime, endTime)。
            
        - 该 API 的后端实现会首先根据文件名筛选出完全或部分落在这个时间区间内的数据文件，然后仅遍历这些文件来查找数据，从而实现高效的范围扫描。
            
    3. **数据降采样与聚合 (Downsampling):**
        
        - 这是时序数据库的核心功能。你可以修改或扩展**文件合并（Compaction）**的过程。
            
        - 当合并一个旧的时间窗口文件时（例如，昨天的原始数据文件），合并进程不再是简单地保留最新值，而是进行**聚合计算**。例如，将每秒一个的数据点，聚合成每分钟一个的平均值/最大值/最小值，然后将这个聚合后的数据点写入新的、分辨率更低的文件中。
            
        - 原始的高精度数据文件在合并后就可以被安全删除了，从而大大节省了存储空间。
            
- **关键词:**  
    时序数据库 (TSDB); 时间序列; 数据降采样; 时间窗口; 范围查询